{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TicTacToe.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM05IJNx4klKtPS+L5c0pAJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rposhala/Tic-Tac-Toe-game-using-Reinforcement-learning/blob/master/TicTacToe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92MBW3PawtcX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jg8gZUFlw0P8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_game(s):\n",
        "    \n",
        "    print('     --------------')\n",
        "    print('       {} | {} | {}'.format(s[0], s[1], s[2]))\n",
        "    print('     --------------')\n",
        "    print('       {} | {} | {}'.format(s[3], s[4], s[5]))\n",
        "    print('     --------------')\n",
        "    print('       {} | {} | {}'.format(s[6], s[7], s[8]))\n",
        "    print('     --------------')\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bI0tWotw2kB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def check_winner(game):\n",
        "    # print(\"game_winner\")\n",
        "    winner = ''\n",
        "    checkfor = [[0, 1, 2], [3, 4, 5], [6, 7, 8], [0, 3, 6], [1, 4, 7], [2, 5, 8], [0, 4, 8], [2, 4, 6]]\n",
        "    for line in checkfor:\n",
        "        s = str(game[line[0]]) + str(game[line[1]]) + str(game[line[2]])\n",
        "        if s == 'XXX':\n",
        "            # winner = 'X'\n",
        "            \n",
        "            winner = 'The winner is PLAYER 1'\n",
        "            break\n",
        "        elif s == 'OOO':\n",
        "            # winner = 'O'\n",
        "            winner = 'The winner is PLAYER 2'\n",
        "            break\n",
        "    # print(game)\n",
        "    # print([type(a) for a in game])\n",
        "    if not any(a for a in game if type(a) != str) and 0 not in game and winner == '':\n",
        "        winner = 'No winner, its a tie'\n",
        "    \n",
        "    \n",
        "    return winner"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkYIj4QQw66i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def inputidx(a):\n",
        "  try :\n",
        "    idx = int(input('Choose move number: '))\n",
        "    if idx in a:\n",
        "      return int(idx)\n",
        "    else :\n",
        "      # print(a)\n",
        "      print(\"please enter a number from the unoccupied places\")\n",
        "      idx = inputidx(a)\n",
        "  except:\n",
        "    # print(a)\n",
        "    print(\"please enter a number\")\n",
        "    idx = inputidx(a)\n",
        "  return idx"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AV517F3Tw_FR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class Sarsa_Agent:\n",
        "    def __init__(self, name, exploration=0.3):\n",
        "        self.name = name\n",
        "        self.terminate = None\n",
        "        self.exploration_rate = exploration\n",
        "        self.discounted_gamma = 0.9\n",
        "        self.learning_rate = 0.2\n",
        "        self.states = []  # record all positions taken\n",
        "        self.dict_state_value = {}  # state -> value\n",
        "        \n",
        "    def NextStep(self, available_positions, current_board_state, turn):\n",
        "        if np.random.uniform(0, 1) <= self.exploration_rate:\n",
        "            # take random action\n",
        "            idx = np.random.choice(len(available_positions))\n",
        "            action = available_positions[idx]\n",
        "        else:\n",
        "            value_max = -999\n",
        "            for i in available_positions:\n",
        "                next_board_state = current_board_state.copy()\n",
        "                next_board_state[i] = turn\n",
        "                next_boardHash = self.getHash(next_board_state)\n",
        "                value = 0 if self.dict_state_value.get(next_boardHash) is None else self.dict_state_value.get(next_boardHash)\n",
        "                if value >= value_max:\n",
        "                    value_max = value\n",
        "                    action = i\n",
        "        # print(\"{} takes action {}\".format(self.name, action))\n",
        "        return action\n",
        "\n",
        "\n",
        "    def getHash(self, game):\n",
        "        gameHash = str(game)\n",
        "        return gameHash\n",
        "\n",
        "\n",
        "    # append a hash state\n",
        "    def addState(self, state):\n",
        "        self.states.append(state)\n",
        "\n",
        "    # at the end of game, backpropagate and update states value\n",
        "    def feedReward(self, reward):\n",
        "        for st in reversed(self.states):\n",
        "            if self.dict_state_value.get(st) is None:\n",
        "                self.dict_state_value[st] = 0\n",
        "            self.dict_state_value[st] += self.learning_rate * (self.discounted_gamma * reward - self.dict_state_value[st])\n",
        "            reward = self.dict_state_value[st]\n",
        "\n",
        "    def reset(self):\n",
        "        self.states = []\n",
        "\n",
        "    def savePolicy(self):\n",
        "        if os.path.exists('policy_' + str(self.name)):\n",
        "          obj = open('policy_' + str(self.name), 'rb')\n",
        "          existing_policies = pickle.load(obj)\n",
        "          for i in existing_policies.keys():\n",
        "            self.dict_state_value[i] = existing_policies[i]\n",
        "            \n",
        "        write_file = open('policy_' + str(self.name), 'wb')\n",
        "        pickle.dump(self.dict_state_value, write_file)\n",
        "        write_file.close()\n",
        "\n",
        "    def loadPolicy(self, file):\n",
        "        read_file = open(file, 'rb')\n",
        "        self.dict_state_value = pickle.load(read_file)\n",
        "        read_file.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzVLOztcxCBV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getHash(game):\n",
        "  return str(game)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZD6A-iHTxEz4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reward(player1,player2,winner):\n",
        "  # print(winner)\n",
        "  if winner == 'The winner is PLAYER 1':\n",
        "    player1.feedReward(1)\n",
        "    player2.feedReward(0)\n",
        "  elif winner == 'The winner is PLAYER 2':\n",
        "    player1.feedReward(0)\n",
        "    player2.feedReward(1)\n",
        "  else :\n",
        "    player1.feedReward(0.1)\n",
        "    player2.feedReward(0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOfr5r-kGJ_8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def agent_training(player1,player2,rounds):\n",
        "\tp1 = 0\n",
        "\tp2 = 0\n",
        "\ttie = 0\n",
        "\tp1_plot = 0\n",
        "\tp2_plot = 0\n",
        "\ttie_plot = 0\n",
        "\tplot_p1 = []\n",
        "\tplot_p2 = []\n",
        "\titerations_count =[]\n",
        "\tplot_tie = []\n",
        "\tfor i in range(rounds):\n",
        "\t\tw = ''\n",
        "\t\ts = list(range(9))\n",
        "\t\tsav = np.zeros(9)\n",
        "\t\tavail = s.copy()\n",
        "\t\ta = s.copy()\n",
        "\t\tturn = ''\n",
        "\t\twhile(w == ''):\n",
        "\t\t\t# Player 1 turn to play\n",
        "\t\t\tturn = 'X'\n",
        "\t\t\tp1_action = player1.NextStep(a, sav, 1)\n",
        "\t\t\tsav[p1_action] = 1\n",
        "\t\t\ts[p1_action] = turn\n",
        "\t\t\ta.remove(p1_action)\n",
        "\t\t\tboard_hash = getHash(sav)\n",
        "\t\t\tplayer1.addState(board_hash)\n",
        "\t\t\twin = check_winner(s)\n",
        "\t\t\tif win != '':\n",
        "\t\t\t\tif win == 'No winner, its a tie':\n",
        "\t\t\t\t\ttie+=1\n",
        "\t\t\t\t\ttie_plot += 1\n",
        "\t\t\t\telse :\n",
        "\t\t\t\t\tp1+=1\n",
        "\t\t\t\t\tp1_plot+=1\n",
        "\t\t\t\treward(player1,player2,win)\n",
        "\t\t\t\tplayer1.reset()\n",
        "\t\t\t\tplayer2.reset()\n",
        "\t\t\t\tbreak\n",
        "\t\t\telse:\n",
        "\t      \t# Player 2 turn to play\n",
        "\t\t\t\tturn = 'O'\n",
        "\t\t\t\tp2_action = player1.NextStep(a, sav, -1)\n",
        "\t\t\t\tsav[p2_action] = -1\n",
        "\t\t\t\ts[p2_action] = turn\n",
        "\t\t\t\ta.remove(p2_action)\n",
        "\t\t\t\tboard_hash = getHash(sav)\n",
        "\t\t\t\tplayer2.addState(board_hash)\n",
        "\t\t\t\twin = check_winner(s)\n",
        "\t\t\t\tif win != '':\n",
        "\t\t\t\t\tif win == 'No winner, its a tie':\n",
        "\t\t\t\t\t\ttie+=1\n",
        "\t\t\t\t\t\ttie_plot += 1\n",
        "\t\t\t\t\telse :\n",
        "\t\t\t\t\t\tp2+=1\n",
        "\t\t\t\t\t\tp2_plot+=1\n",
        "\t\t\t\t\treward(player1,player2,win)\n",
        "\t\t\t\t\tplayer1.reset()\n",
        "\t\t\t\t\tplayer2.reset()\n",
        "\t\t\t\t\tbreak\n",
        "\t\tif (i+1)%500 == 0:\n",
        "\t\t\titerations_count.append(i+1)\n",
        "\t\t\tplot_p1.append(p1_plot)\n",
        "\t\t\tplot_p2.append(p2_plot)\n",
        "\t\t\tplot_tie.append(tie_plot)\n",
        "\t\t\tp1_plot = 0\n",
        "\t\t\tp2_plot = 0\n",
        "\t\t\ttie_plot = 0\n",
        "\n",
        "\tfig = plt.figure()\n",
        "\tplot_figure = fig.add_subplot()\n",
        "\tplot_figure.plot(iterations_count, plot_p1, color='orange')\n",
        "\tplot_figure.plot(iterations_count, plot_p2, color='blue')\n",
        "\tplot_figure.plot(iterations_count, plot_tie, color='green')\n",
        "\tfig.show()\n",
        "\tprint(\"Total iterations: \",rounds)\n",
        "\tprint(\"Player1 (X) wins: \",p1)\n",
        "\tprint(\"Player2 (O) wins: \",p2)\n",
        "\tprint(\"Tie: \",tie)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYZd1BacxKY3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def humanvsagent(agent,name,whichplayer):\n",
        "  w = ''\n",
        "  s = list(range(9))\n",
        "  a = s.copy()\n",
        "  sav = np.zeros(9)\n",
        "  print_game(s)\n",
        "  turn = ''\n",
        "  if whichplayer == 1:\n",
        "    human_turn = 'X'\n",
        "    agent_turn = 'O'\n",
        "    h_no = 1\n",
        "    a_no = -1\n",
        "  else :\n",
        "    human_turn = 'O'\n",
        "    agent_turn = 'X'\n",
        "    h_no = -1\n",
        "    a_no = 1\n",
        "  c = whichplayer\n",
        "  while w == '':\n",
        "    c += 1\n",
        "    if c%2 == 1:\n",
        "      turn = agent_turn\n",
        "      turn1 = a_no\n",
        "      # agent_action = agent.NextStep(a,s,turn)\n",
        "      agent_action = agent.NextStep(a,sav,turn1)\n",
        "      # print(agent_action)\n",
        "      index = agent_action\n",
        "      # s[agent_action] = turn\n",
        "      # a.remove(agent_action)\n",
        "    else :\n",
        "      turn = human_turn\n",
        "      turn1 = h_no\n",
        "      human_action = inputidx(a)\n",
        "      index = human_action\n",
        "\n",
        "    sav[index] = turn1\n",
        "    s[index] = turn\n",
        "    a.remove(index)\n",
        "    print_game(s)\n",
        "    w = check_winner(s)\n",
        "  return w\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIx4cjk5xNl6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hplayer1 = Sarsa_Agent(\"hard_p1\")\n",
        "hplayer2 = Sarsa_Agent(\"hard_p2\")\n",
        "print(\"training...\")\n",
        "agent_training(hplayer1, hplayer2,50000)\n",
        "print(\"done\")\n",
        "hplayer1.savePolicy()\n",
        "hplayer2.savePolicy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeymAD17xXmF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mplayer1 = Sarsa_Agent(\"medium_p1\")\n",
        "mplayer2 = Sarsa_Agent(\"medium_p2\")\n",
        "print(\"training...\")\n",
        "agent_training(mplayer1, mplayer2,7000)\n",
        "print(\"done\")\n",
        "mplayer1.savePolicy()\n",
        "mplayer2.savePolicy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXJJfzUUxjLf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eplayer1 = Sarsa_Agent(\"easy_p1\")\n",
        "eplayer2 = Sarsa_Agent(\"easy_p2\")\n",
        "print(\"training...\")\n",
        "agent_training(eplayer1, eplayer2,1000)\n",
        "print(\"done\")\n",
        "eplayer1.savePolicy()\n",
        "eplayer2.savePolicy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gw1slwl6xvxB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        },
        "outputId": "2627b56c-8bfa-40b8-bacc-8f2fdb37ecc7"
      },
      "source": [
        "p1 = Sarsa_Agent(\"agent\", exploration= 0)\n",
        "p1.loadPolicy(\"policy_hard_p1\") # policy_mplayer1\n",
        "name = 'Rohith'\n",
        "whichplayer = 2\n",
        "result = humanvsagent(p1,name,whichplayer)\n",
        "if result == \"The winner is PLAYER 1\":\n",
        "  if whichplayer == 2:\n",
        "    print(\"Agent wins!\")\n",
        "  else :\n",
        "    print(\"Human wins!\")\n",
        "elif result == \"The winner is PLAYER 2\":\n",
        "  if whichplayer == 1:\n",
        "    print(\"Agent wins!\")\n",
        "  else :\n",
        "    print(\"Human wins!\")\n",
        "else :\n",
        "  print(result)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     --------------\n",
            "       0 | 1 | 2\n",
            "     --------------\n",
            "       3 | 4 | 5\n",
            "     --------------\n",
            "       6 | 7 | 8\n",
            "     --------------\n",
            "     --------------\n",
            "       0 | 1 | 2\n",
            "     --------------\n",
            "       3 | 4 | 5\n",
            "     --------------\n",
            "       X | 7 | 8\n",
            "     --------------\n",
            "Choose move number: 4\n",
            "     --------------\n",
            "       0 | 1 | 2\n",
            "     --------------\n",
            "       3 | O | 5\n",
            "     --------------\n",
            "       X | 7 | 8\n",
            "     --------------\n",
            "     --------------\n",
            "       0 | 1 | 2\n",
            "     --------------\n",
            "       3 | O | 5\n",
            "     --------------\n",
            "       X | X | 8\n",
            "     --------------\n",
            "Choose move number: 1\n",
            "     --------------\n",
            "       0 | O | 2\n",
            "     --------------\n",
            "       3 | O | 5\n",
            "     --------------\n",
            "       X | X | 8\n",
            "     --------------\n",
            "     --------------\n",
            "       0 | O | 2\n",
            "     --------------\n",
            "       3 | O | 5\n",
            "     --------------\n",
            "       X | X | X\n",
            "     --------------\n",
            "Agent wins!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXxQXO6MyqJg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p1 = Sarsa_Agent(\"agent\", exploration= 0)\n",
        "p1.loadPolicy(\"policy_medium_p1\") # policy_mplayer1\n",
        "name = 'Rohith'\n",
        "whichplayer = 2\n",
        "result = humanvsagent(p1,name,whichplayer)\n",
        "if result == \"The winner is PLAYER 1\":\n",
        "  if whichplayer == 2:\n",
        "    print(\"Agent wins!\")\n",
        "  else :\n",
        "    print(\"Human wins!\")\n",
        "elif result == \"The winner is PLAYER 2\":\n",
        "  if whichplayer == 1:\n",
        "    print(\"Agent wins!\")\n",
        "  else :\n",
        "    print(\"Human wins!\")\n",
        "else :\n",
        "  print(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VPP6hElysYy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p1 = Sarsa_Agent(\"agent\", exploration= 0)\n",
        "p1.loadPolicy(\"policy_easy_p1\") # policy_mplayer1\n",
        "name = 'Rohith'\n",
        "whichplayer = 2\n",
        "result = humanvsagent(p1,name,whichplayer)\n",
        "if result == \"The winner is PLAYER 1\":\n",
        "  if whichplayer == 2:\n",
        "    print(\"Agent wins!\")\n",
        "  else :\n",
        "    print(\"Human wins!\")\n",
        "elif result == \"The winner is PLAYER 2\":\n",
        "  if whichplayer == 1:\n",
        "    print(\"Agent wins!\")\n",
        "  else :\n",
        "    print(\"Human wins!\")\n",
        "else :\n",
        "  print(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZgZnwiIyuXx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p1 = Sarsa_Agent(\"agent\", exploration= 0)\n",
        "p1.loadPolicy(\"policy_hard_p2\") # policy_mplayer1\n",
        "name = 'Rohith'\n",
        "whichplayer = 1\n",
        "result = humanvsagent(p1,name,whichplayer)\n",
        "if result == \"The winner is PLAYER 1\":\n",
        "  if whichplayer == 2:\n",
        "    print(\"Agent wins!\")\n",
        "  else :\n",
        "    print(\"Human wins!\")\n",
        "elif result == \"The winner is PLAYER 2\":\n",
        "  if whichplayer == 1:\n",
        "    print(\"Agent wins!\")\n",
        "  else :\n",
        "    print(\"Human wins!\")\n",
        "else :\n",
        "  print(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xO_RNtkLzRwq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p1 = Sarsa_Agent(\"agent\", exploration= 0)\n",
        "p1.loadPolicy(\"policy_medium_p2\") # policy_mplayer1\n",
        "name = 'Rohith'\n",
        "whichplayer = 1\n",
        "result = humanvsagent(p1,name,whichplayer)\n",
        "if result == \"The winner is PLAYER 1\":\n",
        "  if whichplayer == 2:\n",
        "    print(\"Agent wins!\")\n",
        "  else :\n",
        "    print(\"Human wins!\")\n",
        "elif result == \"The winner is PLAYER 2\":\n",
        "  if whichplayer == 1:\n",
        "    print(\"Agent wins!\")\n",
        "  else :\n",
        "    print(\"Human wins!\")\n",
        "else :\n",
        "  print(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQe-4Vm2zST2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p1 = Sarsa_Agent(\"agent\", exploration= 0)\n",
        "p1.loadPolicy(\"policy_easy_p2\") # policy_mplayer1\n",
        "name = 'Rohith'\n",
        "whichplayer = 1\n",
        "result = humanvsagent(p1,name,whichplayer)\n",
        "if result == \"The winner is PLAYER 1\":\n",
        "  if whichplayer == 2:\n",
        "    print(\"Agent wins!\")\n",
        "  else :\n",
        "    print(\"Human wins!\")\n",
        "elif result == \"The winner is PLAYER 2\":\n",
        "  if whichplayer == 1:\n",
        "    print(\"Agent wins!\")\n",
        "  else :\n",
        "    print(\"Human wins!\")\n",
        "else :\n",
        "  print(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcZsd3MBxHHl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def agent_training(player1,player2,rounds):\n",
        "#   for i in range(rounds):\n",
        "#     if i % 10000 == 0:\n",
        "#       print(\"Rounds {}\".format(i))\n",
        "#     w = ''\n",
        "#     s = list(range(9))\n",
        "#     sav = np.zeros(9)\n",
        "#     avail = s.copy()\n",
        "#     a = s.copy()\n",
        "#     # print_game(s)\n",
        "#     turn = ''\n",
        "#     while(w == ''):\n",
        "#        # Player 1\n",
        "#       turn = 'X'\n",
        "#       # p1_action = player1.NextStep(a, s, turn)\n",
        "#       ##\n",
        "#       p1_action = player1.NextStep(a, sav, 1)\n",
        "#       sav[p1_action] = 1\n",
        "\n",
        "#       ##\n",
        "#       s[p1_action] = turn\n",
        "#       a.remove(p1_action)\n",
        "#       # self.updateState(p1_action)\n",
        "#       board_hash = getHash(sav)\n",
        "#       player1.addState(board_hash)\n",
        "#       # check board status if it is end\n",
        "#       # print('p1',a)\n",
        "#       win = check_winner(s)\n",
        "#       if win != '':\n",
        "#         # print('p1_p',a)\n",
        "#         reward(player1,player2,win)\n",
        "#         player1.reset()\n",
        "#         player2.reset()\n",
        "#         # self.reset()\n",
        "#         break\n",
        "#       else:\n",
        "        \n",
        "#         turn = 'O'\n",
        "#         # p2_action = player1.NextStep(a, s, turn)\n",
        "#         # take action and upate board state\n",
        "#         ##\n",
        "#         p2_action = player1.NextStep(a, sav, -1)\n",
        "#         sav[p2_action] = -1\n",
        "#         ##\n",
        "#         s[p2_action] = turn\n",
        "#         a.remove(p2_action)\n",
        "#         # self.updateState(p1_action)\n",
        "#         board_hash = getHash(sav)\n",
        "#         player2.addState(board_hash)\n",
        "#         # print('player2',a)\n",
        "#         win = check_winner(s)\n",
        "#         if win != '':\n",
        "#           # print('p2_p',a)\n",
        "#           reward(player1,player2,win)\n",
        "#           player1.reset()\n",
        "#           player2.reset()\n",
        "#           # self.reset()\n",
        "#           break\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}